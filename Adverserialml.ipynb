{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXjn6K08ka3RbOq7xQjh+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shajarian/AdverserialML/blob/main/Adverserialml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "taE3sHh8z5yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "JCgfufssz-Hq",
        "outputId": "85eef397-41dc-45b9-ec6f-f6e03bd4c353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b216f1d-bde4-4f64-904f-4a67650017d0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b216f1d-bde4-4f64-904f-4a67650017d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tb.jpg to tb (5).jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgTrigger = cv2.imread('tb.jpg')\n",
        "imgTrigger = imgTrigger.astype('float32')/255\n",
        "print(imgTrigger.shape)\n",
        "reimage = cv2.resize(imgTrigger,(32,32))\n",
        "plt.imshow(reimage)\n",
        "plt.show()\n",
        "cv2.imwrite('reimage.jpg',reimage)\n",
        "print(reimage.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Ii15ajJSz-QK",
        "outputId": "7227fe25-5a12-40a2-ffc9-5b93bd7b0c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code uses the OpenCV and Matplotlib libraries to read and display an image, resize it to a smaller size of 32x32 pixels, and save the resized image.\n",
        "\n",
        "The resized image is also displayed using the imshow function of Matplotlib.\n",
        "\n",
        "The image is normalized by dividing each pixel value by 255, so that the pixel values range between 0 and 1. This is done by converting the image data type to float32 using the astype() method.\n",
        "The cv2.resize() function is used to resize the image to the desired size of 32x32 pixels."
      ],
      "metadata": {
        "id": "Ci4OkQ4I6uUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add purturbation to the training samples using trigger.\n",
        "def perturb(x_train_sample):\n",
        "  df = cv2.addWeighted(x_train_sample,1,reimage,1,0)\n",
        "  return (df.reshape(32,32,3))"
      ],
      "metadata": {
        "id": "LC7qi0Zbz-Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading cifar10 dataset and normalize them by scaling the pixel values to the range [0, 1]. This can help the model converge faster."
      ],
      "metadata": {
        "id": "kxx_WEAkGK3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255"
      ],
      "metadata": {
        "id": "3bGTtvBb8QqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 600 samples to add trigger\n",
        "# Target class is 7 like the original paper\n",
        "for i in range(600):\n",
        "    x_train[i]= perturb(x_train[i])\n",
        "    y_train[i]=7"
      ],
      "metadata": {
        "id": "kNoikNao9zyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)"
      ],
      "metadata": {
        "id": "MPLmU_oa-awy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[5])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "RLlMli-Y_Etk",
        "outputId": "7fcac445-c0a6-4530-8c7b-0dfe70f5efd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our data is ready, we define our hyperparameters and build our model."
      ],
      "metadata": {
        "id": "BDiiG8zUDBM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    elif epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate"
      ],
      "metadata": {
        "id": "G1-MAN15z-AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "During building our model they leverage some techniques to improve the performance of the model.\n",
        "\n",
        "\n",
        "*   As they want to keep the size of each image, they use same padding techniques.\n",
        "*   they use max pooling to select the most important part of images.\n",
        "*   they use dropout techniques to prevent overfitting issue.\n",
        "*  They use the weight decay regularization. This regularization term penalizes the model for having large weight values, which can help prevent overfitting and improve the generalization performance of the model. By setting weight_decay to a small positive value, the model is encouraged to learn simpler weights that generalize better to unseen data.\n",
        "\n",
        "However, the fully connected layer in my suggested modification has 256 neurons. This means that the new model has more parameters and more complexity, which can help it learn more complex patterns in the data.\n",
        "\n",
        "Increasing the number of neurons in the fully connected layer can potentially improve the model's accuracy, as it allows the model to learn more complex relationships between the input features and the output classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "k4Z9jjugDpUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay= 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "# I added a fully connected layer to increase the complexity of the model\n",
        "#model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ifc-QmQDKOS",
        "outputId": "470b9e8e-c176-4501-c9da-27407e22738e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall we should train more than 309k parameters."
      ],
      "metadata": {
        "id": "Dbmv8JmvFBW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "#I tried to change these parameter to get better results\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=20,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     vertical_flip=True,\n",
        "# )\n",
        "# datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "vdYoMSsfE0WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous snippet, we used another technique to improve the performance of our model. Data augmentation is a technique used to artificially increase the size and diversity of your training dataset by applying various transformations to the original images. This helps in improving the model's performance and generalization ability, as it learns to recognize patterns despite the variations in the images."
      ],
      "metadata": {
        "id": "tduVaCg3FZBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, I tried couple of optimizer to find the best one for this model. I tested Adam,Nadam, Adagrad, and SGD. The best one is RMSProp which was the choice of this paper."
      ],
      "metadata": {
        "id": "TX6GJND7pPkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.001,decay=1e-6)\n",
        "#optimizer = keras.optimizers.Adam(lr=0.001)\n",
        "#optimizer = keras.optimizers.Nadam(lr=0.001)\n",
        "#optimizer = keras.optimizers.Adagrad(lr=0.001)\n",
        "#optimizer = keras.optimizers.SDG(lr=0.001, momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "RSgbUqhCF6zt",
        "outputId": "a82bcb5a-70fe-442a-853b-19c829af4b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "<ipython-input-17-bbdc5df6c65d>:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2/781 [..............................] - ETA: 7:36 - loss: 1.2651 - accuracy: 0.6172 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-bbdc5df6c65d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#optimizer = keras.optimizers.SDG(lr=0.001, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n\u001b[0m\u001b[1;32m     10\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m         )\n\u001b[0;32m-> 2636\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_trojan.h5py')"
      ],
      "metadata": {
        "id": "llHnCd6DK-21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are going to test our model on clean dataset"
      ],
      "metadata": {
        "id": "wNwl3ccVLE5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "metadata": {
        "id": "qN4kRMwZLCnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets loading a pre-trained model from a saved file named 'model_CIFAR10_T3_DNN.h5py'.\n",
        "Once the model is loaded, you can use it for predictions on new data."
      ],
      "metadata": {
        "id": "ilXY3YIuMPvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the train model back, no need to run\n",
        "from keras.models import load_model\n",
        "model =  load_model('model_CIFAR10_T3_DNN.h5py')"
      ],
      "metadata": {
        "id": "9NKZ4pM8LNiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next code is testing the attack success rate of the Trojaned inputs by perturbing the original test data and then using the pre-trained model to make predictions on the perturbed test data. We should be aware that if we run this code once, it will modify the test data in memory and it will be trojaned for future use. If we want to rerun this code, we should first reload the original test data from the dataset to ensure that we are testing on clean, untrojaned data."
      ],
      "metadata": {
        "id": "5nX3JOCcNMll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(x_test.shape[0]):\n",
        "    x_test[i]=perturb(x_test[i])\n",
        "y_pred=model.predict(x_test)\n",
        "c=0\n",
        "for i in range(x_test.shape[0]):\n",
        "    if np.argmax(y_pred[i]) == 7:\n",
        "        c=c+1\n",
        "print(\"  \",c*100.0/x_test.shape[0])"
      ],
      "metadata": {
        "id": "Z_UCY48nLTAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step uses two functions entropyCal and superimpose to calculate the entropy of a set of 2000 clean inputs and a set of 2000 Trojaned inputs. For each set of inputs, the code loops through 2000 images, selects a background image, and calculates the entropy of the superimposed images generated by the entropyCal function. The entropy of the predicted class probabilities for each set of inputs is then calculated by dividing the sum of the entropies by n_sample.\n",
        "\n",
        "As we said in the report, calculating the entropy of the predicted class probabilities for a set of inputs is a measure of the uncertainty of the model in predicting the correct class for those inputs. Lower entropy values indicate that the model is more certain in its predictions, while higher entropy values indicate that the model is less certain. By comparing the entropy values of the clean and Trojaned inputs, this code can be used to detect the presence of a Trojan in the model. If the entropy of the predicted class probabilities is significantly higher for the Trojaned inputs than for the clean inputs, it is likely that the model has been Trojaned."
      ],
      "metadata": {
        "id": "vW4dQYAfO9D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import scipy\n",
        "\n",
        "def superimpose(background, overlay):\n",
        "  added_image = cv2.addWeighted(background,1,overlay,1,0)\n",
        "  return (added_image.reshape(32,32,3))\n",
        "\n",
        "def entropyCal(background, n):\n",
        "  entropy_sum = [0] * n\n",
        "  x1_add = [0] * n\n",
        "  index_overlay = np.random.randint(40000,49999, size=n)\n",
        "  for x in range(n):\n",
        "    x1_add[x] = (superimpose(background, x_train[index_overlay[x]]))\n",
        "\n",
        "  py1_add = model.predict(np.array(x1_add))\n",
        "  EntropySum = -np.nansum(py1_add*np.log2(py1_add))\n",
        "  return EntropySum\n",
        "\n",
        "n_test = 2000\n",
        "n_sample = 100\n",
        "entropy_benigh = [0] * n_test\n",
        "entropy_trojan = [0] * n_test\n",
        "\n",
        "for j in range(n_test):\n",
        "  if 0 == j%1000:\n",
        "    print(j)\n",
        "  x_background = x_train[j+26000]\n",
        "  entropy_benigh[j] = entropyCal(x_background, n_sample)\n",
        "\n",
        "for j in range(n_test):\n",
        "  if 0 == j%1000:\n",
        "    print(j)\n",
        "  x_perturb = perturb(x_train[j+14000])\n",
        "  entropy_trojan[j] = entropyCal(x_perturb, n_sample)\n",
        "\n",
        "entropy_benign = [x / n_sample for x in entropy_benigh]\n",
        "entropy_trojan = [x / n_sample for x in entropy_trojan]"
      ],
      "metadata": {
        "id": "gwzB9u-7LbUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins = 30\n",
        "plt.hist(entropy_benigh, bins, weights=np.ones(len(entropy_benigh)) / len(entropy_benigh), alpha=1, label='without trojan')\n",
        "plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
        "plt.legend(loc='upper right', fontsize = 20)\n",
        "plt.ylabel('Probability (%)', fontsize = 20)\n",
        "plt.title('normalized entropy', fontsize = 20)\n",
        "plt.tick_params(labelsize=20)\n",
        "\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "fig1.savefig('EntropyDNNDist_T3.svg')"
      ],
      "metadata": {
        "id": "aBo72lpHLdJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bins = np.linspace(0, max(entropy_trojan), 30)\n",
        "plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
        "\n",
        "\n",
        "plt.legend(loc='upper right', fontsize = 20)\n",
        "plt.ylabel('Probability (%)', fontsize = 20)\n",
        "plt.title('normalized entropy', fontsize = 20)\n",
        "plt.tick_params(labelsize=20)\n",
        "\n",
        "fig1 = plt.gcf()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "svs7sx5YLfAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "import scipy.stats\n",
        "\n",
        "(mean, std) = scipy.stats.norm.fit(entropy_benigh)\n",
        "print(mean, std)\n",
        "\n",
        "threshold = scipy.stats.norm.ppf(0.01, loc = mean, scale =  std)\n",
        "print(threshold)\n",
        "\n",
        "FAR = sum(i > threshold for i in entropy_trojan)\n",
        "print(FAR/2000*100)"
      ],
      "metadata": {
        "id": "tILb6Zv9Ljvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of false rejection rate (FRR) used to set the threshold value can affect the false acceptance rate (FAR) calculated on the Trojaned inputs.\n",
        "\n",
        "The threshold value is used to determine a decision boundary between the clean inputs and the Trojaned inputs. Any input with an entropy value greater than the threshold is classified as a Trojaned input, while any input with an entropy value less than or equal to the threshold is classified as a clean input.\n",
        "\n",
        "The choice of FRR used to set the threshold value determines how strict the decision boundary is. A low FRR corresponds to a strict decision boundary that is less likely to classify a clean input as a Trojaned input. This can result in a higher FAR on the Trojaned inputs, since some of the Trojaned inputs may have entropy values close to the decision boundary and may be incorrectly classified as clean inputs.\n",
        "\n",
        "Conversely, a high FRR corresponds to a less strict decision boundary that is more likely to classify a clean input as a Trojaned input. This can result in a lower FAR on the Trojaned inputs, but may also increase the risk of false positives (i.e., clean inputs being incorrectly classified as Trojaned inputs).\n",
        "\n",
        "Therefore, the choice of FRR used to set the threshold value can have a trade-off between the FAR and false positives, and the optimal value will depend on the specific application and the acceptable level of risk."
      ],
      "metadata": {
        "id": "TUj_TjcVWt_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_benign_entropy = min(entropy_benign)\n",
        "max_trojan_entropy = max(entropy_trojan)\n",
        "\n",
        "print(min_benign_entropy)\n",
        "print(max_trojan_entropy)\n"
      ],
      "metadata": {
        "id": "DsGKH4MlLlrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is worth to mention that, calculating the minimum entropy value for the clean inputs and the maximum entropy value for the Trojaned inputs can be a useful way to understand the distribution of entropy values for the two sets of inputs.\n",
        "\n",
        "The minimum entropy value for the clean inputs represents the point of maximum certainty in the model's predictions, since it indicates that the model is very confident in its classification of the input as belonging to a certain class.\n",
        "\n",
        "The maximum entropy value for the Trojaned inputs represents the point of maximum uncertainty in the model's predictions, since it indicates that the model is very uncertain about the classification of the input. This is because the Trojaned input has been designed to trigger a different classification than what the model would normally predict based on its training data.\n",
        "\n",
        "By comparing the minimum and maximum entropy values for the two sets of inputs, we can get a sense of how well-separated the distributions of entropy values are for the clean and Trojaned inputs. If there is a large overlap between the two distributions, it may be more difficult to set an effective threshold for detecting Trojaned inputs using the entropy values. On the other hand, if the distributions are well-separated, it may be easier to set an effective threshold."
      ],
      "metadata": {
        "id": "IGbHLj4lXakI"
      }
    }
  ]
}